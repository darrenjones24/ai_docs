{"Summarize this text in 50 words: \n\n import typing\nimport argparse\nimport os\n\n\nDEFAULT_INCLUDE_SUFFIXES = {\n    \".js\",\n    \".json\",\n    \".jsx\",\n    \".md\",\n    \".py\",\n    \".pyi\",\n    \".pyx\",\n    \".rst\",\n    \".tf\",\n    \".tfvars\",\n    \".ts\",\n    \".tsx\",\n    \".yaml\",\n    \".yml\",\n    \"Dockerfile\",\n    \"Jenkinsfil\",\n}\n\nDEFAULT_EXCLUDE_SUFFIXES = {}\n\nDEFAULT_EXCLUDE_DIRS = {\n    \".git\",\n    \".github\",\n    \".terraform\",\n    \"assets\",\n    \"build\",\n    \"dist\",\n    \"env\",\n    \"docs\",\n    \"env\",\n    \"images\",\n    \"temp\",\n    \"tests\",\n    \"tmp\",\n    \"venv\",\n}\n\n\ndef parse_args() -> typing.Any:\n    \"\"\"\n    Parse command line arguments.\n    :return: Parsed arguments\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Generate documentation for a project using AI.\",\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    parser.add_argument(\n        \"-n\",\n        \"--name\",\n        help=\"local Repository name\",\n        default=\"repo_name\",\n        )\n\n    parser.add_argument(\n        \"-d\",\n        \"--directory\",\n        help=\"top level directory to scan, default is current working directory\",\n        default=os.getcwd(),\n        )\n\n    parser.add_argument(\n        \"-e\",\n        \"--exclude_dirs\",\n        nargs='*',\n        help=\"comma separated list of directories to exclude\",\n        default=\",\"\n        )\n\n    return parser.parse_args()\n\nmodel = os.getenv(\"GEMINI_MODEL\", \"gemini-2.5-pro-exp-03-25\")\nproject=os.getenv(\"GEMINI_PROJECT_ID\", \"sre-ai-dev\")": "This code defines default file suffixes to include/exclude for documentation generation. It also specifies directories to exclude from the scan, like \".git\" and \"venv.\"  The `parse_args` function handles command-line arguments for repository name, directory, and excluded directories.  Finally, it fetches environment variables for the Gemini model and project ID.\n", "Summarize this text in 50 words: \n\n {'settings.py': 'import typing\\nimport argparse\\nimport os\\n\\n\\nDEFAULT_INCLUDE_SUFFIXES = {\\n    \".js\",\\n    \".json\",\\n    \".jsx\",\\n    \".md\",\\n    \".py\",\\n    \".pyi\",\\n    \".pyx\",\\n    \".rst\",\\n    \".tf\",\\n    \".tfvars\",\\n    \".ts\",\\n    \".tsx\",\\n    \".yaml\",\\n    \".yml\",\\n    \"Dockerfile\",\\n    \"Jenkinsfil\",\\n}\\n\\nDEFAULT_EXCLUDE_SUFFIXES = {}\\n\\nDEFAULT_EXCLUDE_DIRS = {\\n    \".git\",\\n    \".github\",\\n    \".terraform\",\\n    \"assets\",\\n    \"build\",\\n    \"dist\",\\n    \"env\",\\n    \"docs\",\\n    \"env\",\\n    \"images\",\\n    \"temp\",\\n    \"tests\",\\n    \"tmp\",\\n    \"venv\",\\n}\\n\\n\\ndef parse_args() -> typing.Any:\\n    \"\"\"\\n    Parse command line arguments.\\n    :return: Parsed arguments\\n    \"\"\"\\n    parser = argparse.ArgumentParser(\\n        description=\"Generate documentation for a project using AI.\",\\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\\n    )\\n\\n    parser.add_argument(\\n        \"-n\",\\n        \"--name\",\\n        help=\"local Repository name\",\\n        default=\"repo_name\",\\n        )\\n\\n    parser.add_argument(\\n        \"-d\",\\n        \"--directory\",\\n        help=\"top level directory to scan, default is current working directory\",\\n        default=os.getcwd(),\\n        )\\n\\n    parser.add_argument(\\n        \"-e\",\\n        \"--exclude_dirs\",\\n        nargs=\\'*\\',\\n        help=\"comma separated list of directories to exclude\",\\n        default=\",\"\\n        )\\n\\n    return parser.parse_args()\\n\\nmodel = os.getenv(\"GEMINI_MODEL\", \"gemini-2.5-pro-exp-03-25\")\\nproject=os.getenv(\"GEMINI_PROJECT_ID\", \"sre-ai-dev\")', 'llm_cache.json': '{\"Summarize this text in 50 words: \\\\n\\\\n import typing\\\\nimport argparse\\\\nimport os\\\\n\\\\n\\\\nDEFAULT_INCLUDE_SUFFIXES = {\\\\n    \\\\\".js\\\\\",\\\\n    \\\\\".json\\\\\",\\\\n    \\\\\".jsx\\\\\",\\\\n    \\\\\".md\\\\\",\\\\n    \\\\\".py\\\\\",\\\\n    \\\\\".pyi\\\\\",\\\\n    \\\\\".pyx\\\\\",\\\\n    \\\\\".rst\\\\\",\\\\n    \\\\\".tf\\\\\",\\\\n    \\\\\".tfvars\\\\\",\\\\n    \\\\\".ts\\\\\",\\\\n    \\\\\".tsx\\\\\",\\\\n    \\\\\".yaml\\\\\",\\\\n    \\\\\".yml\\\\\",\\\\n    \\\\\"Dockerfile\\\\\",\\\\n    \\\\\"Jenkinsfil\\\\\",\\\\n}\\\\n\\\\nDEFAULT_EXCLUDE_SUFFIXES = {}\\\\n\\\\nDEFAULT_EXCLUDE_DIRS = {\\\\n    \\\\\".git\\\\\",\\\\n    \\\\\".github\\\\\",\\\\n    \\\\\".terraform\\\\\",\\\\n    \\\\\"assets\\\\\",\\\\n    \\\\\"build\\\\\",\\\\n    \\\\\"dist\\\\\",\\\\n    \\\\\"env\\\\\",\\\\n    \\\\\"docs\\\\\",\\\\n    \\\\\"env\\\\\",\\\\n    \\\\\"images\\\\\",\\\\n    \\\\\"temp\\\\\",\\\\n    \\\\\"tests\\\\\",\\\\n    \\\\\"tmp\\\\\",\\\\n    \\\\\"venv\\\\\",\\\\n}\\\\n\\\\n\\\\ndef parse_args() -> typing.Any:\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    Parse command line arguments.\\\\n    :return: Parsed arguments\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    parser = argparse.ArgumentParser(\\\\n        description=\\\\\"Generate documentation for a project using AI.\\\\\",\\\\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\\\\n    )\\\\n\\\\n    parser.add_argument(\\\\n        \\\\\"-n\\\\\",\\\\n        \\\\\"--name\\\\\",\\\\n        help=\\\\\"local Repository name\\\\\",\\\\n        default=\\\\\"repo_name\\\\\",\\\\n        )\\\\n\\\\n    parser.add_argument(\\\\n        \\\\\"-d\\\\\",\\\\n        \\\\\"--directory\\\\\",\\\\n        help=\\\\\"top level directory to scan, default is current working directory\\\\\",\\\\n        default=os.getcwd(),\\\\n        )\\\\n\\\\n    parser.add_argument(\\\\n        \\\\\"-e\\\\\",\\\\n        \\\\\"--exclude_dirs\\\\\",\\\\n        nargs=\\'*\\',\\\\n        help=\\\\\"comma separated list of directories to exclude\\\\\",\\\\n        default=\\\\\",\\\\\"\\\\n        )\\\\n\\\\n    return parser.parse_args()\\\\n\\\\nmodel = os.getenv(\\\\\"GEMINI_MODEL\\\\\", \\\\\"gemini-2.5-pro-exp-03-25\\\\\")\\\\nproject=os.getenv(\\\\\"GEMINI_PROJECT_ID\\\\\", \\\\\"sre-ai-dev\\\\\")\": \"This code defines default file suffixes to include/exclude for documentation generation. It also specifies directories to exclude from the scan, like \\\\\".git\\\\\" and \\\\\"venv.\\\\\"  The `parse_args` function handles command-line arguments for repository name, directory, and excluded directories.  Finally, it fetches environment variables for the Gemini model and project ID.\\\\n\"}', 'fetch_files.py': '# A script to crawl files from a given directory and its subdirectories.\\n# It uses the `os` module to walk through the directory structure and collects file paths based on specified include and exclude patterns.\\n# files that are not in the exclude patterns and are in the include patterns are collected.\\nimport os\\nimport typing\\nimport logging\\nfrom pathlib import Path\\nfrom settings import DEFAULT_EXCLUDE_SUFFIXES, DEFAULT_INCLUDE_SUFFIXES, DEFAULT_EXCLUDE_DIRS\\n\\n\\n\\ndef crawl_files(\\n    directory: str,\\n    include_patterns: typing.Set[str] = DEFAULT_INCLUDE_SUFFIXES,\\n    exclude_suffixes: typing.Set[str] = DEFAULT_EXCLUDE_SUFFIXES,\\n    exclude_dirs: typing.Set[str] = DEFAULT_EXCLUDE_DIRS,\\n    ) -> typing.List[str]:\\n    try:\\n        files = {\\n            str(item.relative_to(directory))  # Store the relative path string\\n            for item in Path(directory).rglob(\"*\") # Iterate through all items recursively\\n            if item.is_file() # Consider only files\\n            if item.suffix in include_patterns # Check 0: Suffix is included\\n            and item.suffix not in exclude_suffixes # Check 1: Suffix is not excluded\\n            and not any(part in exclude_dirs for part in item.relative_to(directory).parts) # Check 2: No path part is excluded\\n        }\\n\\n    except ValueError as e:\\n        logging.error(f\"Error calculating relative paths: {e}\")\\n        logging.error(f\"Ensure the search directory \\'{directory.resolve()}\\' is within or is the \"\\n            f\"current working directory \\'{directory.resolve()}\\'\")\\n\\n    logging.info(f\"Found {len(files)} files in {directory}\")\\n    logging.debug(f\"Files found: {files}\")\\n\\n    return files\\n\\n\\ndef main() -> None:\\n    print(\"Crawling files...\")\\n    directory = os.getcwd()  \\n    print(f\"Files crawled from {directory}:\")\\n    print (crawl_files(directory))\\n\\nif __name__ == \"__main__\":\\n    main()', 'nodes.py': 'from pocketflow import Node\\nfrom call_llm import call_llm\\n\\n\\nclass Summarise(Node):\\n    \"\"\"\\n    This class identifies abstractions in the code.\\n    \"\"\"\\n\\n    def prep(self,shared):\\n        return shared_settings[\"data\"][\"settings.py\"]\\n    \\n    def exec(self, text):\\n        prompt = f\"Summarize this text in 50 words: \\\\n\\\\n {text}\"\\n        return call_llm(prompt)\\n    \\n    def post(self, shared, prep_res, exec_res):\\n        # Store the result in the shared settings\\n        shared_settings[\"summaries\"] = exec_res\\n        return \"default\"\\n    \\nfile_contents = {\\n    \"data\": {},\\n    \"summaries\": None\\n}\\n\\n# with open(\"settings.py\", \"r\") as f:\\n#     shared_settings[\"data\"][\"settings.py\"] = f.read()\\n\\n# summarise_node = Summarise()\\n# summarise_node.run(shared_settings)\\n\\n# print(f\"Summary: {shared_settings[\\'summaries\\']}\")', '__init__.py': '', 'call_llm.py': 'from google import genai\\nimport os\\nimport logging\\nimport json\\nfrom datetime import datetime\\nimport requests\\n\\n# Configure logging\\nlog_directory = os.getenv(\"LOG_DIR\", \"logs\")\\nos.makedirs(log_directory, exist_ok=True)\\nlog_file = os.path.join(\\n    log_directory, f\"llm_calls_{datetime.now().strftime(\\'%Y%m%d\\')}.log\"\\n)\\n\\n# Set up logger\\nlogger = logging.getLogger(\"llm_logger\")\\nlogger.setLevel(logging.INFO)\\nlogger.propagate = False  # Prevent propagation to root logger\\nfile_handler = logging.FileHandler(log_file)\\nfile_handler.setFormatter(\\n    logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\\n)\\nlogger.addHandler(file_handler)\\n\\n# Simple cache configuration\\ncache_file = \"llm_cache.json\"\\n\\n\\n# By default, we Google Gemini 2.5 pro, as it shows great performance for code understanding\\ndef call_llm(prompt: str, use_cache: bool = True) -> str:\\n    # Log the prompt\\n    logger.info(f\"PROMPT: {prompt}\")\\n\\n    # Check cache if enabled\\n    if use_cache:\\n        # Load cache from disk\\n        cache = {}\\n        if os.path.exists(cache_file):\\n            try:\\n                with open(cache_file, \"r\") as f:\\n                    cache = json.load(f)\\n            except:\\n                logger.warning(f\"Failed to load cache, starting with empty cache\")\\n\\n        # Return from cache if exists\\n        if prompt in cache:\\n            logger.info(f\"RESPONSE: {cache[prompt]}\")\\n            return cache[prompt]\\n\\n    # Call the LLM if not in cache or cache disabled\\n    client = genai.Client(\\n        vertexai=True,\\n        # TODO: change to your own project id and location\\n        project=os.getenv(\"GEMINI_PROJECT_ID\", \"ai-sre-dev-84b7\"),\\n        location=os.getenv(\"GEMINI_LOCATION\", \"us-central1\")\\n    )\\n\\n    model = os.getenv(\"GEMINI_MODEL\", \"gemini-2.0-flash-exp\")\\n    \\n    response = client.models.generate_content(model=model, contents=[prompt])\\n    response_text = response.text\\n\\n    # Log the response\\n    logger.info(f\"RESPONSE: {response_text}\")\\n\\n    # Update cache if enabled\\n    if use_cache:\\n        # Load cache again to avoid overwrites\\n        cache = {}\\n        if os.path.exists(cache_file):\\n            try:\\n                with open(cache_file, \"r\") as f:\\n                    cache = json.load(f)\\n            except:\\n                pass\\n\\n        # Add to cache and save\\n        cache[prompt] = response_text\\n        try:\\n            with open(cache_file, \"w\") as f:\\n                json.dump(cache, f)\\n        except Exception as e:\\n            logger.error(f\"Failed to save cache: {e}\")\\n\\n    return response_text\\n\\n\\nif __name__ == \"__main__\":\\n    test_prompt = \"Hello, how are you?\"\\n\\n    # First call - should hit the API\\n    print(\"Making call...\")\\n    response1 = call_llm(test_prompt, use_cache=False)\\n    print(f\"Response: {response1}\")\\n', 'main.py': 'import argparse\\nimport os\\nimport sys\\nimport typing\\nimport logging\\nfrom pocketflow import Node\\nfrom call_llm import call_llm\\nfrom settings import (\\n    DEFAULT_EXCLUDE_SUFFIXES,\\n    DEFAULT_INCLUDE_SUFFIXES,\\n    DEFAULT_EXCLUDE_DIRS,\\n)\\nfrom settings import parse_args\\nimport fetch_files\\n\\n\\nclass Summarise(Node):\\n    \"\"\"\\n    This class identifies abstractions in the code.\\n    \"\"\"\\n\\n    def prep(self,shared):\\n        return file_contents[\"data\"]\\n    \\n    def exec(self, text):\\n        prompt = f\"Summarize this text in 50 words: \\\\n\\\\n {text}\"\\n        return call_llm(prompt)\\n    \\n    def post(self, shared, prep_res, exec_res):\\n        # Store the result in the shared settings\\n        file_contents[\"summaries\"] = exec_res\\n        return \"default\"\\n    \\nfile_contents = {\\n\"data\": {},\\n\"summaries\": None\\n}\\n\\n\\ndef main() -> None:\\n    args = parse_args()\\n\\n    # create a dictionarty of settings to be used in the script\\n    shared_settings = {\\n        \"name\": args.name,\\n        \"directory\": args.directory,\\n        \"exclude_patterns\": DEFAULT_EXCLUDE_SUFFIXES,\\n        \"exclude_dirs\": DEFAULT_EXCLUDE_DIRS,\\n        \"include_suffixes\": DEFAULT_INCLUDE_SUFFIXES,\\n        \"additional_exclude_dirs\": args.exclude_dirs,\\n    }\\n    logging.debug(f\"Shared settings: {shared_settings}\")\\n\\n    # Get a list of files from the directory and its subdirectories and append to the shared settings\\n    shared_settings[\"files\"] = fetch_files.crawl_files(\\n        directory=shared_settings[\"directory\"],\\n        exclude_dirs=shared_settings[\"exclude_dirs\"].union(\\n            shared_settings[\"additional_exclude_dirs\"]\\n        ),\\n    )\\n\\n\\n\\n    for file in shared_settings[\"files\"]:\\n        with open(file, \"r\") as f:\\n            file_contents[\"data\"][file] = f.read()\\n    print(f\"File contents: {file_contents}\")\\n    \\n    summarise_node = Summarise()\\n    summarise_node.run(file_contents[\"data\"])\\n\\n    print(f\"Summary: {file_contents[\\'summaries\\']}\")\\n\\n    # print (shared_settings)\\n\\n\\nif __name__ == \"__main__\":\\n    main()\\n'}": "The code generates project documentation using AI. It defines default file types to include/exclude and directories to skip during scanning. Command-line arguments customize the repository name, scan directory, and excluded directories. It crawls files and utilizes a Gemini model via API calls to summarize the content, storing results in a cache.", "Summarize this text in 50 words: \n\n {'settings.py': 'import typing\\nimport argparse\\nimport os\\n\\n\\nDEFAULT_INCLUDE_SUFFIXES = {\\n    \".js\",\\n    \".json\",\\n    \".jsx\",\\n    \".md\",\\n    \".py\",\\n    \".pyi\",\\n    \".pyx\",\\n    \".rst\",\\n    \".tf\",\\n    \".tfvars\",\\n    \".ts\",\\n    \".tsx\",\\n    \".yaml\",\\n    \".yml\",\\n    \"Dockerfile\",\\n    \"Jenkinsfil\",\\n}\\n\\nDEFAULT_EXCLUDE_SUFFIXES = {}\\n\\nDEFAULT_EXCLUDE_DIRS = {\\n    \".git\",\\n    \".github\",\\n    \".terraform\",\\n    \"assets\",\\n    \"build\",\\n    \"dist\",\\n    \"env\",\\n    \"docs\",\\n    \"env\",\\n    \"images\",\\n    \"temp\",\\n    \"tests\",\\n    \"tmp\",\\n    \"venv\",\\n}\\n\\n\\ndef parse_args() -> typing.Any:\\n    \"\"\"\\n    Parse command line arguments.\\n    :return: Parsed arguments\\n    \"\"\"\\n    parser = argparse.ArgumentParser(\\n        description=\"Generate documentation for a project using AI.\",\\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\\n    )\\n\\n    parser.add_argument(\\n        \"-n\",\\n        \"--name\",\\n        help=\"local Repository name\",\\n        default=\"repo_name\",\\n        )\\n\\n    parser.add_argument(\\n        \"-d\",\\n        \"--directory\",\\n        help=\"top level directory to scan, default is current working directory\",\\n        default=os.getcwd(),\\n        )\\n\\n    parser.add_argument(\\n        \"-e\",\\n        \"--exclude_dirs\",\\n        nargs=\\'*\\',\\n        help=\"comma separated list of directories to exclude\",\\n        default=\",\"\\n        )\\n\\n    return parser.parse_args()\\n\\nmodel = os.getenv(\"GEMINI_MODEL\", \"gemini-2.5-pro-exp-03-25\")\\nproject=os.getenv(\"GEMINI_PROJECT_ID\", \"sre-ai-dev\")', '__init__.py': '', 'main.py': 'import logging\\nfrom pocketflow import Node\\nfrom call_llm import call_llm\\nfrom settings import (\\n    DEFAULT_EXCLUDE_SUFFIXES,\\n    DEFAULT_INCLUDE_SUFFIXES,\\n    DEFAULT_EXCLUDE_DIRS,\\n)\\nfrom settings import parse_args\\nimport fetch_files\\n\\n\\nclass Summarise(Node):\\n    \"\"\"\\n    This class identifies abstractions in the code.\\n    \"\"\"\\n\\n    def prep(self,shared):\\n        return file_contents[\"data\"]\\n    \\n    def exec(self, text):\\n        prompt = f\"Summarize this text in 50 words: \\\\n\\\\n {text}\"\\n        return call_llm(prompt)\\n    \\n    def post(self, shared, prep_res, exec_res):\\n        # Store the result in the shared settings\\n        file_contents[\"summaries\"] = exec_res\\n        return \"default\"\\n\\n\\nfile_contents = {\\n\"data\": {},\\n\"summaries\": None\\n}\\n\\n\\ndef main() -> None:\\n    args = parse_args()\\n\\n    # create a dictionarty of settings to be used in the script\\n    shared_settings = {\\n        \"name\": args.name,\\n        \"directory\": args.directory,\\n        \"exclude_patterns\": DEFAULT_EXCLUDE_SUFFIXES,\\n        \"exclude_dirs\": DEFAULT_EXCLUDE_DIRS,\\n        \"include_suffixes\": DEFAULT_INCLUDE_SUFFIXES,\\n        \"additional_exclude_dirs\": args.exclude_dirs,\\n    }\\n    logging.debug(f\"Shared settings: {shared_settings}\")\\n\\n    # Get a list of files from the directory and its subdirectories and append to the shared settings\\n    shared_settings[\"files\"] = fetch_files.crawl_files(\\n        directory=shared_settings[\"directory\"],\\n        exclude_dirs=shared_settings[\"exclude_dirs\"].union(\\n            shared_settings[\"additional_exclude_dirs\"]\\n        ),\\n    )\\n\\n    for file in shared_settings[\"files\"]:\\n        with open(file, \"r\") as f:\\n            file_contents[\"data\"][file] = f.read()\\n    \\n    summarise_node = Summarise()\\n    summarise_node.run(file_contents[\"data\"])\\n\\n    print(f\"Summary: {file_contents[\\'summaries\\']}\")\\n\\n    # print (shared_settings)\\n\\n\\nif __name__ == \"__main__\":\\n    main()\\n', 'fetch_files.py': '# A script to crawl files from a given directory and its subdirectories.\\n# It uses the `os` module to walk through the directory structure and collects file paths based on specified include and exclude patterns.\\n# files that are not in the exclude patterns and are in the include patterns are collected.\\nimport os\\nimport typing\\nimport logging\\nfrom pathlib import Path\\nfrom settings import DEFAULT_EXCLUDE_SUFFIXES, DEFAULT_INCLUDE_SUFFIXES, DEFAULT_EXCLUDE_DIRS\\n\\n\\n\\ndef crawl_files(\\n    directory: str,\\n    include_patterns: typing.Set[str] = DEFAULT_INCLUDE_SUFFIXES,\\n    exclude_suffixes: typing.Set[str] = DEFAULT_EXCLUDE_SUFFIXES,\\n    exclude_dirs: typing.Set[str] = DEFAULT_EXCLUDE_DIRS,\\n    ) -> typing.List[str]:\\n    try:\\n        files = {\\n            str(item.relative_to(directory))  # Store the relative path string\\n            for item in Path(directory).rglob(\"*\") # Iterate through all items recursively\\n            if item.is_file() # Consider only files\\n            if item.suffix in include_patterns # Check 0: Suffix is included\\n            and item.suffix not in exclude_suffixes # Check 1: Suffix is not excluded\\n            and not any(part in exclude_dirs for part in item.relative_to(directory).parts) # Check 2: No path part is excluded\\n        }\\n\\n    except ValueError as e:\\n        logging.error(f\"Error calculating relative paths: {e}\")\\n        logging.error(f\"Ensure the search directory \\'{directory.resolve()}\\' is within or is the \"\\n            f\"current working directory \\'{directory.resolve()}\\'\")\\n\\n    logging.info(f\"Found {len(files)} files in {directory}\")\\n    logging.debug(f\"Files found: {files}\")\\n\\n    return files\\n\\n\\ndef main() -> None:\\n    print(\"Crawling files...\")\\n    directory = os.getcwd()  \\n    print(f\"Files crawled from {directory}:\")\\n    print (crawl_files(directory))\\n\\nif __name__ == \"__main__\":\\n    main()', 'call_llm.py': 'from google import genai\\nimport os\\nimport logging\\nimport json\\nfrom datetime import datetime\\n\\n\\n# Configure logging\\nlog_directory = os.getenv(\"LOG_DIR\", \"logs\")\\nos.makedirs(log_directory, exist_ok=True)\\nlog_file = os.path.join(\\n    log_directory, f\"llm_calls_{datetime.now().strftime(\\'%Y%m%d\\')}.log\"\\n)\\n\\n# Set up logger\\nlogger = logging.getLogger(\"llm_logger\")\\nlogger.setLevel(logging.INFO)\\nlogger.propagate = False  # Prevent propagation to root logger\\nfile_handler = logging.FileHandler(log_file)\\nfile_handler.setFormatter(\\n    logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\\n)\\nlogger.addHandler(file_handler)\\n\\n# Simple cache configuration\\ncache_file = \"llm_cache.json\"\\n\\n\\ndef call_llm(prompt: str, use_cache: bool = True) -> str:\\n    # Log the prompt\\n    logger.info(f\"PROMPT: {prompt}\")\\n\\n    # Check cache if enabled\\n    if use_cache:\\n        # Load cache from disk\\n        cache = {}\\n        if os.path.exists(cache_file):\\n            try:\\n                with open(cache_file, \"r\") as f:\\n                    cache = json.load(f)\\n            except:\\n                logger.warning(f\"Failed to load cache, starting with empty cache\")\\n\\n        # Return from cache if exists\\n        if prompt in cache:\\n            logger.info(f\"RESPONSE: {cache[prompt]}\")\\n            return cache[prompt]\\n\\n    # Call the LLM if not in cache or cache disabled\\n    client = genai.Client(\\n        vertexai=True,\\n        project=os.getenv(\"GEMINI_PROJECT_ID\", \"ai-sre-dev-84b7\"),\\n        location=os.getenv(\"GEMINI_LOCATION\", \"us-central1\")\\n    )\\n\\n    model = os.getenv(\"GEMINI_MODEL\", \"gemini-2.0-flash-exp\")\\n    \\n    response = client.models.generate_content(model=model, contents=[prompt])\\n    response_text = response.text\\n\\n    # Log the response\\n    logger.info(f\"RESPONSE: {response_text}\")\\n\\n    # Update cache if enabled\\n    if use_cache:\\n        # Load cache again to avoid overwrites\\n        cache = {}\\n        if os.path.exists(cache_file):\\n            try:\\n                with open(cache_file, \"r\") as f:\\n                    cache = json.load(f)\\n            except:\\n                pass\\n\\n        # Add to cache and save\\n        cache[prompt] = response_text\\n        try:\\n            with open(cache_file, \"w\") as f:\\n                json.dump(cache, f)\\n        except Exception as e:\\n            logger.error(f\"Failed to save cache: {e}\")\\n\\n    return response_text\\n\\n\\nif __name__ == \"__main__\":\\n    test_prompt = \"Hello, how are you?\"\\n\\n    # First call - should hit the API\\n    print(\"Making call...\")\\n    response1 = call_llm(test_prompt, use_cache=False)\\n    print(f\"Response: {response1}\")\\n', 'llm_cache.json': '{\"Summarize this text in 50 words: \\\\n\\\\n import typing\\\\nimport argparse\\\\nimport os\\\\n\\\\n\\\\nDEFAULT_INCLUDE_SUFFIXES = {\\\\n    \\\\\".js\\\\\",\\\\n    \\\\\".json\\\\\",\\\\n    \\\\\".jsx\\\\\",\\\\n    \\\\\".md\\\\\",\\\\n    \\\\\".py\\\\\",\\\\n    \\\\\".pyi\\\\\",\\\\n    \\\\\".pyx\\\\\",\\\\n    \\\\\".rst\\\\\",\\\\n    \\\\\".tf\\\\\",\\\\n    \\\\\".tfvars\\\\\",\\\\n    \\\\\".ts\\\\\",\\\\n    \\\\\".tsx\\\\\",\\\\n    \\\\\".yaml\\\\\",\\\\n    \\\\\".yml\\\\\",\\\\n    \\\\\"Dockerfile\\\\\",\\\\n    \\\\\"Jenkinsfil\\\\\",\\\\n}\\\\n\\\\nDEFAULT_EXCLUDE_SUFFIXES = {}\\\\n\\\\nDEFAULT_EXCLUDE_DIRS = {\\\\n    \\\\\".git\\\\\",\\\\n    \\\\\".github\\\\\",\\\\n    \\\\\".terraform\\\\\",\\\\n    \\\\\"assets\\\\\",\\\\n    \\\\\"build\\\\\",\\\\n    \\\\\"dist\\\\\",\\\\n    \\\\\"env\\\\\",\\\\n    \\\\\"docs\\\\\",\\\\n    \\\\\"env\\\\\",\\\\n    \\\\\"images\\\\\",\\\\n    \\\\\"temp\\\\\",\\\\n    \\\\\"tests\\\\\",\\\\n    \\\\\"tmp\\\\\",\\\\n    \\\\\"venv\\\\\",\\\\n}\\\\n\\\\n\\\\ndef parse_args() -> typing.Any:\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    Parse command line arguments.\\\\n    :return: Parsed arguments\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    parser = argparse.ArgumentParser(\\\\n        description=\\\\\"Generate documentation for a project using AI.\\\\\",\\\\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\\\\n    )\\\\n\\\\n    parser.add_argument(\\\\n        \\\\\"-n\\\\\",\\\\n        \\\\\"--name\\\\\",\\\\n        help=\\\\\"local Repository name\\\\\",\\\\n        default=\\\\\"repo_name\\\\\",\\\\n        )\\\\n\\\\n    parser.add_argument(\\\\n        \\\\\"-d\\\\\",\\\\n        \\\\\"--directory\\\\\",\\\\n        help=\\\\\"top level directory to scan, default is current working directory\\\\\",\\\\n        default=os.getcwd(),\\\\n        )\\\\n\\\\n    parser.add_argument(\\\\n        \\\\\"-e\\\\\",\\\\n        \\\\\"--exclude_dirs\\\\\",\\\\n        nargs=\\'*\\',\\\\n        help=\\\\\"comma separated list of directories to exclude\\\\\",\\\\n        default=\\\\\",\\\\\"\\\\n        )\\\\n\\\\n    return parser.parse_args()\\\\n\\\\nmodel = os.getenv(\\\\\"GEMINI_MODEL\\\\\", \\\\\"gemini-2.5-pro-exp-03-25\\\\\")\\\\nproject=os.getenv(\\\\\"GEMINI_PROJECT_ID\\\\\", \\\\\"sre-ai-dev\\\\\")\": \"This code defines default file suffixes to include/exclude for documentation generation. It also specifies directories to exclude from the scan, like \\\\\".git\\\\\" and \\\\\"venv.\\\\\"  The `parse_args` function handles command-line arguments for repository name, directory, and excluded directories.  Finally, it fetches environment variables for the Gemini model and project ID.\\\\n\", \"Summarize this text in 50 words: \\\\n\\\\n {\\'settings.py\\': \\'import typing\\\\\\\\nimport argparse\\\\\\\\nimport os\\\\\\\\n\\\\\\\\n\\\\\\\\nDEFAULT_INCLUDE_SUFFIXES = {\\\\\\\\n    \\\\\".js\\\\\",\\\\\\\\n    \\\\\".json\\\\\",\\\\\\\\n    \\\\\".jsx\\\\\",\\\\\\\\n    \\\\\".md\\\\\",\\\\\\\\n    \\\\\".py\\\\\",\\\\\\\\n    \\\\\".pyi\\\\\",\\\\\\\\n    \\\\\".pyx\\\\\",\\\\\\\\n    \\\\\".rst\\\\\",\\\\\\\\n    \\\\\".tf\\\\\",\\\\\\\\n    \\\\\".tfvars\\\\\",\\\\\\\\n    \\\\\".ts\\\\\",\\\\\\\\n    \\\\\".tsx\\\\\",\\\\\\\\n    \\\\\".yaml\\\\\",\\\\\\\\n    \\\\\".yml\\\\\",\\\\\\\\n    \\\\\"Dockerfile\\\\\",\\\\\\\\n    \\\\\"Jenkinsfil\\\\\",\\\\\\\\n}\\\\\\\\n\\\\\\\\nDEFAULT_EXCLUDE_SUFFIXES = {}\\\\\\\\n\\\\\\\\nDEFAULT_EXCLUDE_DIRS = {\\\\\\\\n    \\\\\".git\\\\\",\\\\\\\\n    \\\\\".github\\\\\",\\\\\\\\n    \\\\\".terraform\\\\\",\\\\\\\\n    \\\\\"assets\\\\\",\\\\\\\\n    \\\\\"build\\\\\",\\\\\\\\n    \\\\\"dist\\\\\",\\\\\\\\n    \\\\\"env\\\\\",\\\\\\\\n    \\\\\"docs\\\\\",\\\\\\\\n    \\\\\"env\\\\\",\\\\\\\\n    \\\\\"images\\\\\",\\\\\\\\n    \\\\\"temp\\\\\",\\\\\\\\n    \\\\\"tests\\\\\",\\\\\\\\n    \\\\\"tmp\\\\\",\\\\\\\\n    \\\\\"venv\\\\\",\\\\\\\\n}\\\\\\\\n\\\\\\\\n\\\\\\\\ndef parse_args() -> typing.Any:\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n    Parse command line arguments.\\\\\\\\n    :return: Parsed arguments\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n    parser = argparse.ArgumentParser(\\\\\\\\n        description=\\\\\"Generate documentation for a project using AI.\\\\\",\\\\\\\\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\\\\\\\\n    )\\\\\\\\n\\\\\\\\n    parser.add_argument(\\\\\\\\n        \\\\\"-n\\\\\",\\\\\\\\n        \\\\\"--name\\\\\",\\\\\\\\n        help=\\\\\"local Repository name\\\\\",\\\\\\\\n        default=\\\\\"repo_name\\\\\",\\\\\\\\n        )\\\\\\\\n\\\\\\\\n    parser.add_argument(\\\\\\\\n        \\\\\"-d\\\\\",\\\\\\\\n        \\\\\"--directory\\\\\",\\\\\\\\n        help=\\\\\"top level directory to scan, default is current working directory\\\\\",\\\\\\\\n        default=os.getcwd(),\\\\\\\\n        )\\\\\\\\n\\\\\\\\n    parser.add_argument(\\\\\\\\n        \\\\\"-e\\\\\",\\\\\\\\n        \\\\\"--exclude_dirs\\\\\",\\\\\\\\n        nargs=\\\\\\\\\\'*\\\\\\\\\\',\\\\\\\\n        help=\\\\\"comma separated list of directories to exclude\\\\\",\\\\\\\\n        default=\\\\\",\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n    return parser.parse_args()\\\\\\\\n\\\\\\\\nmodel = os.getenv(\\\\\"GEMINI_MODEL\\\\\", \\\\\"gemini-2.5-pro-exp-03-25\\\\\")\\\\\\\\nproject=os.getenv(\\\\\"GEMINI_PROJECT_ID\\\\\", \\\\\"sre-ai-dev\\\\\")\\', \\'llm_cache.json\\': \\'{\\\\\"Summarize this text in 50 words: \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n import typing\\\\\\\\\\\\\\\\nimport argparse\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nDEFAULT_INCLUDE_SUFFIXES = {\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".js\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".json\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".jsx\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".md\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".pyi\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".pyx\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".rst\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".tf\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".tfvars\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".ts\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".tsx\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".yaml\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".yml\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\"Dockerfile\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\"Jenkinsfil\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nDEFAULT_EXCLUDE_SUFFIXES = {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nDEFAULT_EXCLUDE_DIRS = {\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".git\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".github\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\".terraform\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\"assets\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\"build\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\"dist\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\"env\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\"docs\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\"env\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\"images\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\"temp\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\"tests\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\"tmp\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\"venv\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef parse_args() -> typing.Any:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Parse command line arguments.\\\\\\\\\\\\\\\\n    :return: Parsed arguments\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    parser = argparse.ArgumentParser(\\\\\\\\\\\\\\\\n        description=\\\\\\\\\\\\\\\\\\\\\"Generate documentation for a project using AI.\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\\\\\\\\\\\\\\\\n    )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    parser.add_argument(\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\"-n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\"--name\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        help=\\\\\\\\\\\\\\\\\\\\\"local Repository name\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        default=\\\\\\\\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    parser.add_argument(\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\"-d\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\"--directory\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        help=\\\\\\\\\\\\\\\\\\\\\"top level directory to scan, default is current working directory\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        default=os.getcwd(),\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    parser.add_argument(\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\"-e\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\"--exclude_dirs\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        nargs=\\\\\\\\\\'*\\\\\\\\\\',\\\\\\\\\\\\\\\\n        help=\\\\\\\\\\\\\\\\\\\\\"comma separated list of directories to exclude\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        default=\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return parser.parse_args()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nmodel = os.getenv(\\\\\\\\\\\\\\\\\\\\\"GEMINI_MODEL\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\"gemini-2.5-pro-exp-03-25\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nproject=os.getenv(\\\\\\\\\\\\\\\\\\\\\"GEMINI_PROJECT_ID\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\"sre-ai-dev\\\\\\\\\\\\\\\\\\\\\")\\\\\": \\\\\"This code defines default file suffixes to include/exclude for documentation generation. It also specifies directories to exclude from the scan, like \\\\\\\\\\\\\\\\\\\\\".git\\\\\\\\\\\\\\\\\\\\\" and \\\\\\\\\\\\\\\\\\\\\"venv.\\\\\\\\\\\\\\\\\\\\\"  The `parse_args` function handles command-line arguments for repository name, directory, and excluded directories.  Finally, it fetches environment variables for the Gemini model and project ID.\\\\\\\\\\\\\\\\n\\\\\"}\\', \\'fetch_files.py\\': \\'# A script to crawl files from a given directory and its subdirectories.\\\\\\\\n# It uses the `os` module to walk through the directory structure and collects file paths based on specified include and exclude patterns.\\\\\\\\n# files that are not in the exclude patterns and are in the include patterns are collected.\\\\\\\\nimport os\\\\\\\\nimport typing\\\\\\\\nimport logging\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom settings import DEFAULT_EXCLUDE_SUFFIXES, DEFAULT_INCLUDE_SUFFIXES, DEFAULT_EXCLUDE_DIRS\\\\\\\\n\\\\\\\\n\\\\\\\\n\\\\\\\\ndef crawl_files(\\\\\\\\n    directory: str,\\\\\\\\n    include_patterns: typing.Set[str] = DEFAULT_INCLUDE_SUFFIXES,\\\\\\\\n    exclude_suffixes: typing.Set[str] = DEFAULT_EXCLUDE_SUFFIXES,\\\\\\\\n    exclude_dirs: typing.Set[str] = DEFAULT_EXCLUDE_DIRS,\\\\\\\\n    ) -> typing.List[str]:\\\\\\\\n    try:\\\\\\\\n        files = {\\\\\\\\n            str(item.relative_to(directory))  # Store the relative path string\\\\\\\\n            for item in Path(directory).rglob(\\\\\"*\\\\\") # Iterate through all items recursively\\\\\\\\n            if item.is_file() # Consider only files\\\\\\\\n            if item.suffix in include_patterns # Check 0: Suffix is included\\\\\\\\n            and item.suffix not in exclude_suffixes # Check 1: Suffix is not excluded\\\\\\\\n            and not any(part in exclude_dirs for part in item.relative_to(directory).parts) # Check 2: No path part is excluded\\\\\\\\n        }\\\\\\\\n\\\\\\\\n    except ValueError as e:\\\\\\\\n        logging.error(f\\\\\"Error calculating relative paths: {e}\\\\\")\\\\\\\\n        logging.error(f\\\\\"Ensure the search directory \\\\\\\\\\'{directory.resolve()}\\\\\\\\\\' is within or is the \\\\\"\\\\\\\\n            f\\\\\"current working directory \\\\\\\\\\'{directory.resolve()}\\\\\\\\\\'\\\\\")\\\\\\\\n\\\\\\\\n    logging.info(f\\\\\"Found {len(files)} files in {directory}\\\\\")\\\\\\\\n    logging.debug(f\\\\\"Files found: {files}\\\\\")\\\\\\\\n\\\\\\\\n    return files\\\\\\\\n\\\\\\\\n\\\\\\\\ndef main() -> None:\\\\\\\\n    print(\\\\\"Crawling files...\\\\\")\\\\\\\\n    directory = os.getcwd()  \\\\\\\\n    print(f\\\\\"Files crawled from {directory}:\\\\\")\\\\\\\\n    print (crawl_files(directory))\\\\\\\\n\\\\\\\\nif __name__ == \\\\\"__main__\\\\\":\\\\\\\\n    main()\\', \\'nodes.py\\': \\'from pocketflow import Node\\\\\\\\nfrom call_llm import call_llm\\\\\\\\n\\\\\\\\n\\\\\\\\nclass Summarise(Node):\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n    This class identifies abstractions in the code.\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n\\\\\\\\n    def prep(self,shared):\\\\\\\\n        return shared_settings[\\\\\"data\\\\\"][\\\\\"settings.py\\\\\"]\\\\\\\\n    \\\\\\\\n    def exec(self, text):\\\\\\\\n        prompt = f\\\\\"Summarize this text in 50 words: \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n {text}\\\\\"\\\\\\\\n        return call_llm(prompt)\\\\\\\\n    \\\\\\\\n    def post(self, shared, prep_res, exec_res):\\\\\\\\n        # Store the result in the shared settings\\\\\\\\n        shared_settings[\\\\\"summaries\\\\\"] = exec_res\\\\\\\\n        return \\\\\"default\\\\\"\\\\\\\\n    \\\\\\\\nfile_contents = {\\\\\\\\n    \\\\\"data\\\\\": {},\\\\\\\\n    \\\\\"summaries\\\\\": None\\\\\\\\n}\\\\\\\\n\\\\\\\\n# with open(\\\\\"settings.py\\\\\", \\\\\"r\\\\\") as f:\\\\\\\\n#     shared_settings[\\\\\"data\\\\\"][\\\\\"settings.py\\\\\"] = f.read()\\\\\\\\n\\\\\\\\n# summarise_node = Summarise()\\\\\\\\n# summarise_node.run(shared_settings)\\\\\\\\n\\\\\\\\n# print(f\\\\\"Summary: {shared_settings[\\\\\\\\\\'summaries\\\\\\\\\\']}\\\\\")\\', \\'__init__.py\\': \\'\\', \\'call_llm.py\\': \\'from google import genai\\\\\\\\nimport os\\\\\\\\nimport logging\\\\\\\\nimport json\\\\\\\\nfrom datetime import datetime\\\\\\\\nimport requests\\\\\\\\n\\\\\\\\n# Configure logging\\\\\\\\nlog_directory = os.getenv(\\\\\"LOG_DIR\\\\\", \\\\\"logs\\\\\")\\\\\\\\nos.makedirs(log_directory, exist_ok=True)\\\\\\\\nlog_file = os.path.join(\\\\\\\\n    log_directory, f\\\\\"llm_calls_{datetime.now().strftime(\\\\\\\\\\'%Y%m%d\\\\\\\\\\')}.log\\\\\"\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Set up logger\\\\\\\\nlogger = logging.getLogger(\\\\\"llm_logger\\\\\")\\\\\\\\nlogger.setLevel(logging.INFO)\\\\\\\\nlogger.propagate = False  # Prevent propagation to root logger\\\\\\\\nfile_handler = logging.FileHandler(log_file)\\\\\\\\nfile_handler.setFormatter(\\\\\\\\n    logging.Formatter(\\\\\"%(asctime)s - %(levelname)s - %(message)s\\\\\")\\\\\\\\n)\\\\\\\\nlogger.addHandler(file_handler)\\\\\\\\n\\\\\\\\n# Simple cache configuration\\\\\\\\ncache_file = \\\\\"llm_cache.json\\\\\"\\\\\\\\n\\\\\\\\n\\\\\\\\n# By default, we Google Gemini 2.5 pro, as it shows great performance for code understanding\\\\\\\\ndef call_llm(prompt: str, use_cache: bool = True) -> str:\\\\\\\\n    # Log the prompt\\\\\\\\n    logger.info(f\\\\\"PROMPT: {prompt}\\\\\")\\\\\\\\n\\\\\\\\n    # Check cache if enabled\\\\\\\\n    if use_cache:\\\\\\\\n        # Load cache from disk\\\\\\\\n        cache = {}\\\\\\\\n        if os.path.exists(cache_file):\\\\\\\\n            try:\\\\\\\\n                with open(cache_file, \\\\\"r\\\\\") as f:\\\\\\\\n                    cache = json.load(f)\\\\\\\\n            except:\\\\\\\\n                logger.warning(f\\\\\"Failed to load cache, starting with empty cache\\\\\")\\\\\\\\n\\\\\\\\n        # Return from cache if exists\\\\\\\\n        if prompt in cache:\\\\\\\\n            logger.info(f\\\\\"RESPONSE: {cache[prompt]}\\\\\")\\\\\\\\n            return cache[prompt]\\\\\\\\n\\\\\\\\n    # Call the LLM if not in cache or cache disabled\\\\\\\\n    client = genai.Client(\\\\\\\\n        vertexai=True,\\\\\\\\n        # TODO: change to your own project id and location\\\\\\\\n        project=os.getenv(\\\\\"GEMINI_PROJECT_ID\\\\\", \\\\\"ai-sre-dev-84b7\\\\\"),\\\\\\\\n        location=os.getenv(\\\\\"GEMINI_LOCATION\\\\\", \\\\\"us-central1\\\\\")\\\\\\\\n    )\\\\\\\\n\\\\\\\\n    model = os.getenv(\\\\\"GEMINI_MODEL\\\\\", \\\\\"gemini-2.0-flash-exp\\\\\")\\\\\\\\n    \\\\\\\\n    response = client.models.generate_content(model=model, contents=[prompt])\\\\\\\\n    response_text = response.text\\\\\\\\n\\\\\\\\n    # Log the response\\\\\\\\n    logger.info(f\\\\\"RESPONSE: {response_text}\\\\\")\\\\\\\\n\\\\\\\\n    # Update cache if enabled\\\\\\\\n    if use_cache:\\\\\\\\n        # Load cache again to avoid overwrites\\\\\\\\n        cache = {}\\\\\\\\n        if os.path.exists(cache_file):\\\\\\\\n            try:\\\\\\\\n                with open(cache_file, \\\\\"r\\\\\") as f:\\\\\\\\n                    cache = json.load(f)\\\\\\\\n            except:\\\\\\\\n                pass\\\\\\\\n\\\\\\\\n        # Add to cache and save\\\\\\\\n        cache[prompt] = response_text\\\\\\\\n        try:\\\\\\\\n            with open(cache_file, \\\\\"w\\\\\") as f:\\\\\\\\n                json.dump(cache, f)\\\\\\\\n        except Exception as e:\\\\\\\\n            logger.error(f\\\\\"Failed to save cache: {e}\\\\\")\\\\\\\\n\\\\\\\\n    return response_text\\\\\\\\n\\\\\\\\n\\\\\\\\nif __name__ == \\\\\"__main__\\\\\":\\\\\\\\n    test_prompt = \\\\\"Hello, how are you?\\\\\"\\\\\\\\n\\\\\\\\n    # First call - should hit the API\\\\\\\\n    print(\\\\\"Making call...\\\\\")\\\\\\\\n    response1 = call_llm(test_prompt, use_cache=False)\\\\\\\\n    print(f\\\\\"Response: {response1}\\\\\")\\\\\\\\n\\', \\'main.py\\': \\'import argparse\\\\\\\\nimport os\\\\\\\\nimport sys\\\\\\\\nimport typing\\\\\\\\nimport logging\\\\\\\\nfrom pocketflow import Node\\\\\\\\nfrom call_llm import call_llm\\\\\\\\nfrom settings import (\\\\\\\\n    DEFAULT_EXCLUDE_SUFFIXES,\\\\\\\\n    DEFAULT_INCLUDE_SUFFIXES,\\\\\\\\n    DEFAULT_EXCLUDE_DIRS,\\\\\\\\n)\\\\\\\\nfrom settings import parse_args\\\\\\\\nimport fetch_files\\\\\\\\n\\\\\\\\n\\\\\\\\nclass Summarise(Node):\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n    This class identifies abstractions in the code.\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n\\\\\\\\n    def prep(self,shared):\\\\\\\\n        return file_contents[\\\\\"data\\\\\"]\\\\\\\\n    \\\\\\\\n    def exec(self, text):\\\\\\\\n        prompt = f\\\\\"Summarize this text in 50 words: \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n {text}\\\\\"\\\\\\\\n        return call_llm(prompt)\\\\\\\\n    \\\\\\\\n    def post(self, shared, prep_res, exec_res):\\\\\\\\n        # Store the result in the shared settings\\\\\\\\n        file_contents[\\\\\"summaries\\\\\"] = exec_res\\\\\\\\n        return \\\\\"default\\\\\"\\\\\\\\n    \\\\\\\\nfile_contents = {\\\\\\\\n\\\\\"data\\\\\": {},\\\\\\\\n\\\\\"summaries\\\\\": None\\\\\\\\n}\\\\\\\\n\\\\\\\\n\\\\\\\\ndef main() -> None:\\\\\\\\n    args = parse_args()\\\\\\\\n\\\\\\\\n    # create a dictionarty of settings to be used in the script\\\\\\\\n    shared_settings = {\\\\\\\\n        \\\\\"name\\\\\": args.name,\\\\\\\\n        \\\\\"directory\\\\\": args.directory,\\\\\\\\n        \\\\\"exclude_patterns\\\\\": DEFAULT_EXCLUDE_SUFFIXES,\\\\\\\\n        \\\\\"exclude_dirs\\\\\": DEFAULT_EXCLUDE_DIRS,\\\\\\\\n        \\\\\"include_suffixes\\\\\": DEFAULT_INCLUDE_SUFFIXES,\\\\\\\\n        \\\\\"additional_exclude_dirs\\\\\": args.exclude_dirs,\\\\\\\\n    }\\\\\\\\n    logging.debug(f\\\\\"Shared settings: {shared_settings}\\\\\")\\\\\\\\n\\\\\\\\n    # Get a list of files from the directory and its subdirectories and append to the shared settings\\\\\\\\n    shared_settings[\\\\\"files\\\\\"] = fetch_files.crawl_files(\\\\\\\\n        directory=shared_settings[\\\\\"directory\\\\\"],\\\\\\\\n        exclude_dirs=shared_settings[\\\\\"exclude_dirs\\\\\"].union(\\\\\\\\n            shared_settings[\\\\\"additional_exclude_dirs\\\\\"]\\\\\\\\n        ),\\\\\\\\n    )\\\\\\\\n\\\\\\\\n\\\\\\\\n\\\\\\\\n    for file in shared_settings[\\\\\"files\\\\\"]:\\\\\\\\n        with open(file, \\\\\"r\\\\\") as f:\\\\\\\\n            file_contents[\\\\\"data\\\\\"][file] = f.read()\\\\\\\\n    print(f\\\\\"File contents: {file_contents}\\\\\")\\\\\\\\n    \\\\\\\\n    summarise_node = Summarise()\\\\\\\\n    summarise_node.run(file_contents[\\\\\"data\\\\\"])\\\\\\\\n\\\\\\\\n    print(f\\\\\"Summary: {file_contents[\\\\\\\\\\'summaries\\\\\\\\\\']}\\\\\")\\\\\\\\n\\\\\\\\n    # print (shared_settings)\\\\\\\\n\\\\\\\\n\\\\\\\\nif __name__ == \\\\\"__main__\\\\\":\\\\\\\\n    main()\\\\\\\\n\\'}\": \"The code generates project documentation using AI. It defines default file types to include/exclude and directories to skip during scanning. Command-line arguments customize the repository name, scan directory, and excluded directories. It crawls files and utilizes a Gemini model via API calls to summarize the content, storing results in a cache.\"}'}": "This project generates documentation using AI. It crawls project files, excluding specified directories and file types. The code uses the Gemini model to summarize file contents, caching the results. Command-line arguments customize the project name, scan directory, and exclusion rules for processing files.\n"}